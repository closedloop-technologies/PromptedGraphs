{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698fa025",
   "metadata": {},
   "source": [
    "# Entity Recognition Pipeline\n",
    "\n",
    "Implement a trainable end-to-end entity recognition and linking pipeline \n",
    "leveraging a database schemas to query for entities\n",
    "\n",
    "[https://spacy.io/api/coref](https://spacy.io/api/coref)\n",
    "\n",
    "[https://explosion.ai/blog/coref](https://explosion.ai/blog/coref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd5cab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sean/.cache/pypoetry/virtualenvs/promptedgraphs-6U6kQWDY-py3.10/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c40e562-5698-4ea7-aec4-3cb7b9426340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: spacy_experimental: command not found\n"
     ]
    }
   ],
   "source": [
    "!spacy_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3d39bfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "3.7.2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpromptedgraphs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m render_entities\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpromptedgraphs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EntityReference\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m spacy\u001b[38;5;241m.\u001b[39m__version__ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.4.4\u001b[39m\u001b[38;5;124m\"\u001b[39m, spacy\u001b[38;5;241m.\u001b[39m__version__\n",
      "\u001b[0;31mAssertionError\u001b[0m: 3.7.2"
     ]
    }
   ],
   "source": [
    "# !pip install https://github.com/explosion/spacy-experimental/releases/download/v0.6.1/en_coreference_web_trf-3.4.0a2-py3-none-any.whl\n",
    "\n",
    "import spacy\n",
    "import spacy_experimental\n",
    "from spacy.tokens import Doc\n",
    "import pandas as pd\n",
    "from promptedgraphs.vis import render_entities\n",
    "from promptedgraphs.models import EntityReference\n",
    "\n",
    "assert spacy.__version__ == \"3.4.4\", spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7752d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0e8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b73f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_coref = spacy.load(\"en_coreference_web_trf\", vocab=nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_coref(\"The cats were startled by the dog as it growled at them.\")\n",
    "doc.spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_coref.replace_listeners(\"transformer\", \"coref\", ['model.tok2vec'])\n",
    "nlp_coref.replace_listeners(\"transformer\", \"span_resolver\", ['model.tok2vec'])\n",
    "\n",
    "nlp.add_pipe(\"coref\", source=nlp_coref)\n",
    "nlp.add_pipe(\"span_resolver\", source=nlp_coref)\n",
    "\n",
    "doc = nlp(\"The cats were startled by the dog as it growled at them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5d775-6f42-4655-b008-9d3d191d4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c74648-3938-420c-b36c-2b99847e43c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a lightweight function for resolving references in text, excluding generic terms\n",
    "def resolve_references(doc: Doc) -> str:\n",
    "    \"\"\"Function for resolving references with the coref output, excluding generic terms.\n",
    "    doc (Doc): The Doc object processed by the coref pipeline.\n",
    "    RETURNS (str): The Doc string with resolved references.\n",
    "    \"\"\"\n",
    "    # Define generic terms to exclude\n",
    "    generic_terms = {'he', 'she', 'it', 'them', 'his', 'her', 'its', 'their', 'they'}\n",
    "    \n",
    "    # token.idx : replacement_text\n",
    "    token_mention_mapper = {}\n",
    "    output_string = \"\"\n",
    "    clusters = [\n",
    "        val for key, val in doc.spans.items() if key.startswith(\"coref_cluster\")\n",
    "    ]\n",
    "\n",
    "    # Iterate through every found cluster\n",
    "    for cluster in clusters:\n",
    "        # Find the first non-generic mention in the cluster\n",
    "        first_mention = next((span for span in cluster if span[0].lower_ not in generic_terms), cluster[0])\n",
    "\n",
    "        # Iterate through every span in the cluster\n",
    "        for mention_span in cluster:\n",
    "            if mention_span != first_mention:\n",
    "                # Set first_mention as the replacement for the first token in mention_span\n",
    "                token_mention_mapper[mention_span[0].idx] = first_mention.text + mention_span[0].whitespace_\n",
    "                for token in mention_span[1:]:\n",
    "                    # Set empty string for all other tokens in mention_span\n",
    "                    token_mention_mapper[token.idx] = \"\"\n",
    "\n",
    "    # Iterate through every token in the Doc\n",
    "    for token in doc:\n",
    "        # Check if token exists in token_mention_mapper and add replacement or original text\n",
    "        output_string += token_mention_mapper.get(token.idx, token.text + token.whitespace_)\n",
    "\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f02b6-5855-4262-b249-a151f8c6d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# nlp = spacy.load(\"en_core_web_sm\")  # Make sure to load your coreference model or pipeline instead\n",
    "text = \"John said that he would attend the meeting. He arrived late.\"  # Example text\n",
    "doc = nlp(text)  # Assuming 'doc' has been processed by a coreference resolution pipeline\n",
    "\n",
    "resolved_text = resolve_references(doc)\n",
    "print(resolved_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539684bc-2bbc-4a31-adac-d3e69dc75453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_coreference_web_trf\")\n",
    "\n",
    "text = [\"Philip plays the bass because he loves it.\",\n",
    "\"Sam thanked the doctor for helping him.\",\n",
    "\"Tina drover the car to the shops because they were about to close.\"]\n",
    "\n",
    "df = pd.DataFrame(text, columns=['text'])\n",
    "\n",
    "df['text-coref'] = [resolve_references(coref_doc) for coref_doc in nlp.pipe(df['text'])]\n",
    "\n",
    "for txt in df['text-coref']:\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = next(nlp.pipe(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76deb0b-6538-4252-aa63-ce9614443a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_references(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7bab3-672c-412e-ab52-5922918f4766",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927f8f4-10c2-4ed1-a70e-26dc73fe50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.spans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd173cc-9294-4d5b-8128-d3b00a240df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4276aa-73f8-43a6-8ddf-4247a76b5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(resolve_references(doc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfab86d-d5ea-4af3-83e9-c023f2f4312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2.spans['coref_clusters_1'][1].start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d503bef-da68-43df-910f-e6269cabecdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145b302-87a0-48fb-a784-186c46fde1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = list(doc2.ents)[0]\n",
    "e.label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95efc6-9219-4bc7-8ba7-0ac3e6a5970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_entities(doc.text, [EntityReference(e.start_char, e.end_char, label=e.label_, text=e.text) for e in list(doc.ents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3ff369-586d-4c08-a87b-9b44be858517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptedgraphs.vis import render_entities\n",
    "\n",
    "render_entities(doc.text, [EntityReference(e.start_char, e.end_char, label=e.label_, text=e.text) for e in list(doc2.ents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c80d6-2fc8-44d0-a1c4-3e5c743e6f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Yesterday, Google announced its own AI chatbot, Bard, a competitor to ChatGPT, developed by OpenAI. However, the tech giant embarrassed itself by sharing an inaccurate information generated with the new platform. As a result, the company's stock plunged pretrading before recouping its losses during the day.\"\n",
    "doc = nlp(text)\n",
    "print(doc.spans)\n",
    "\n",
    "render_entities(doc.text, [EntityReference(e.start_char, e.end_char, label=e.label_, text=e.text) for e in list(doc.ents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8704ea-cffd-41d2-9ad3-84cbe090a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fcb0af-4535-44d8-9dfb-049904907f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_entities(doc.text, [EntityReference(e.start_char, e.end_char, label=e.label_, text=e.text) for e in list(doc.ents)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6332def7-e539-4fd1-92c1-4d619d16afbf",
   "metadata": {},
   "source": [
    "# Natural language understanding steps\n",
    "\n",
    "1. Understand the sentence structure and coreference resolutions\n",
    "2. What is the information provided by the question? (Create an ER graph)\n",
    "3. Map this information to domain-specific schemas we know about (Entity Recognition)\n",
    "4. What is the query intent?\n",
    "5. Planning Steps to query information (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4dfa4-dbba-4126-9dc4-759433753c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/emorynlp/elit/tree/main\n",
    "# !poetry add git+https://github.com/python-poetry/poetry.git#develop/dev-candidate-1\n",
    "!poetry add amrlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ac1ef0-4761-485e-87a2-a5f558b2e6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d0349-eeb7-4a6e-a573-7b131097381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/bjascob/amrlib-models/releases\n",
    "# !wget -O /usr/local/data/amr_models/model_parse_t5-v0_2_0.tar.gz https://github.com/bjascob/amrlib-models/releases/download/model_parse_t5-v0_2_0/model_parse_t5-v0_2_0.tar.gz\n",
    "# !tar -xzvf /usr/local/data/amr_models/model_parse_t5-v0_2_0.tar.gz -C /usr/local/data/amr_models/\n",
    "\n",
    "# https://github.com/bjascob/amrlib-models/releases/download/parse_xfm_bart_base-v0_1_0/model_parse_xfm_bart_base-v0_1_0.tar.gz\n",
    "# !wget -O /usr/local/data/amr_models/model_parse_xfm_bart_base-v0_1_0.tar.gz https://github.com/bjascob/amrlib-models/releases/download/parse_xfm_bart_base-v0_1_0/model_parse_xfm_bart_base-v0_1_0.tar.gz\n",
    "# !tar -xzvf /usr/local/data/amr_models/model_parse_xfm_bart_base-v0_1_0.tar.gz -C /usr/local/data/amr_models/\n",
    "\n",
    "# !wget -O /usr/local/data/amr_models/model_parse_xfm_bart_large-v0_1_0.tar.gz https://github.com/bjascob/amrlib-models/releases/download/parse_xfm_bart_large-v0_1_0/model_parse_xfm_bart_large-v0_1_0.tar.gz\n",
    "# !tar -xzvf /usr/local/data/amr_models/model_parse_xfm_bart_large-v0_1_0.tar.gz -C /usr/local/data/amr_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2224336-4c2b-4faf-98d8-17f9eb7eefbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec789f-892c-4733-94ac-e05b481d860b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc132b58-b8ab-4e45-879c-7420d0c45d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec93557e-9c7c-4ee0-8023-7f8da3d6ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amr_model_dir = '/usr/local/data/amr_models/model_stog'\n",
    "amr_model_dir = '/usr/local/data/amr_models/model_parse_t5-v0_2_0'\n",
    "stog = amrlib.load_stog_model(model_dir=amr_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f082530-2c9e-45f9-9b85-4287943825e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import amrlib\n",
    "graphs = stog.parse_sents(['This is a test of the system.', 'This is a second sentence.'])\n",
    "for graph in graphs:\n",
    "    print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29af9b03-35fe-42cf-8536-ae8e21b1e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = stog.parse_sents([str(doc.text)])\n",
    "for graph in graphs:\n",
    "    print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001cf99-44c9-4f03-982e-7dddc7e49a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e0cd3-8925-4aaf-906d-f3e83fcdcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde81b1a-f772-4c47-ad00-d208bbf23458",
   "metadata": {},
   "outputs": [],
   "source": [
    "penman_graph = penman.parse(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b6633-6e5f-4eb2-84ea-06228e2c440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "penman_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc7ec1-9e1f-4ede-940a-de35b7e7c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import amrlib\n",
    "import spacy\n",
    "amrlib.setup_spacy_extension()\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "\n",
    "# The following are roughly equivalent but demonstrate the different objects.\n",
    "graphs = doc._.to_amr()\n",
    "for graph in graphs:\n",
    "    print(graph)\n",
    "\n",
    "# for span in doc.sents:\n",
    "#     graphs = span._.to_amr()\n",
    "#     print(graphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d165c24-8798-4540-8ed5-3e7b3484df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from   amrlib.graph_processing.amr_plot import AMRPlot\n",
    "from   amrlib.graph_processing.amr_loading import load_amr_entries\n",
    "# input_file = 'amrlib/data/LDC2020T02/test.txt'\n",
    "# # Load the AMR file\n",
    "# entries = load_amr_entries(input_file)\n",
    "# entry = entries[125]    # pick an index\n",
    "# # Plot\n",
    "plot = AMRPlot()\n",
    "plot.build_from_graph(graph, debug=False)\n",
    "plot.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3d9ad-7153-40b2-b2bd-fc1bd49ce733",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39064488-71d6-4f8d-945c-8bd2b41ec99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the function for simple Semantic Role Labeling (SRL)\n",
    "def simple_srl(sentence, nlp):\n",
    "    doc = nlp(sentence)\n",
    "    subjects = []\n",
    "    verbs = []\n",
    "    objects = []\n",
    "    indirect_objects = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if \"subj\" in token.dep_:\n",
    "            subjects.append(token.text)\n",
    "        if \"VERB\" in token.pos_:\n",
    "            verbs.append(token.lemma_)\n",
    "        if \"obj\" in token.dep_:\n",
    "            objects.append(token.text)\n",
    "        if \"dative\" in token.dep_:\n",
    "            indirect_objects.append(token.text)\n",
    "            \n",
    "    return {\n",
    "        'subjects': subjects,\n",
    "        'verbs': verbs,\n",
    "        'objects': objects,\n",
    "        'indirect_objects': indirect_objects\n",
    "    }\n",
    "\n",
    "def build_and_plot_knowledge_graph_matplotlib(srl_results):\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    for result in srl_results:\n",
    "        subjects = result['subjects']\n",
    "        verbs = result['verbs']\n",
    "        objects = result['objects']\n",
    "        indirect_objects = result['indirect_objects']\n",
    "        \n",
    "        for subject in subjects:\n",
    "            for verb in verbs:\n",
    "                for obj in objects:\n",
    "                    G.add_edge(subject, obj, label=verb)\n",
    "                for ind_obj in indirect_objects:\n",
    "                    G.add_edge(subject, ind_obj, label=verb)\n",
    "    \n",
    "    pos = nx.spring_layout(G, seed=20)\n",
    "    \n",
    "    # Draw nodes and edges\n",
    "    nx.draw(G, pos, with_labels=True, node_color=\"skyblue\", node_size=2000, font_size=12, font_color=\"black\", font_weight=\"bold\", arrows=True)\n",
    "    \n",
    "    # Draw edge labels\n",
    "    edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "# Process each sentence and extract SRL results\n",
    "srl_results = []\n",
    "for sent in nlp(text).sents:\n",
    "    result = simple_srl(sent.text, nlp)\n",
    "    srl_results.append(result)\n",
    "\n",
    "# Build and plot the knowledge graph with matplotlib\n",
    "build_and_plot_knowledge_graph_matplotlib(srl_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209dc878-5ac3-459d-83c0-a4b6ebb0b6f1",
   "metadata": {},
   "source": [
    "## Better Semantic Role Labeling\n",
    "\n",
    "https://luheng.github.io/files/acl2017_hllz.pdf\n",
    "\n",
    "https://github.com/luheng/deep_srl\n",
    "\n",
    "https://paperswithcode.com/task/semantic-role-labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee137636-0b2c-4a3e-8e60-ca3172be3c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PromptedGraphs (poetry\n\n)",
   "language": "python",
   "name": "promptedgraphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
